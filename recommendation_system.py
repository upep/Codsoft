# -*- coding: utf-8 -*-
"""recommendation_system.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/17CPufTgWn7xbpM5QeIMgFoPDWDe-jVRa
"""

! curl https://files.grouplens.org/datasets/movielens/ml-latest-small.zip -o ml-latest-small.zip

import zipfile

with zipfile.ZipFile('ml-latest-small.zip', 'r') as zip_ref:
        zip_ref.extractall('data')

import pandas as pd

movies_df=pd.read_csv('data/ml-latest-small/movies.csv')
ratings_df=pd.read_csv('data/ml-latest-small/ratings.csv')

print("The dimensions of movies ataframe are :", movies_df.shape,"\nThe dimensions of the ratings dataframe are:",ratings_df.shape)

movies_df.head()

ratings_df.head()

movies_names=movies_df.set_index('movieId')['title'].to_dict()
n_users=len(ratings_df.userId.unique())
n_items=len(ratings_df.movieId.unique())

import  torch
import numpy as np
from torch.autograd import Variable
from tqdm import tqdm_notebook as tqdm

class MatrixFactorization(torch.nn.Module):
    def __init__(self,n_users,n_items,n_factors=20):
      super().__init__()
      self.user_factors=torch.nn.Embedding(n_users,n_factors)
      self.item_factors=torch.nn.Embedding(n_items,n_factors)
      self.user_factors.weight.data.uniform_(0,0.05)
      self.item_factors.weight.data.uniform_(0,0.05)

    def forward(self,data):
      users,items=data[:,0] ,data[:,1]
      return (self.user_factors(users)*self.item_factors(items)).sum(1)

    def predict (self,user,item):
      return self.forward(user,item)

from torch.utils.data.dataset import Dataset
from torch.utils.data import DataLoader

class loader(Dataset):
  def __init__(self):
    self.ratings=ratings_df.copy()


    users=ratings_df.userId.unique()
    movies=ratings_df.movieId.unique()

    self.userid2idx ={o:i for i,o in enumerate(users)}
    self.movieid2idx ={o:i for i,o in enumerate(movies)}

    self.idx2userid ={o:i for i,o in self.userid2idx.items()}
    self.idx2movieid ={o:i for i,o in self.movieid2idx.items()}

    self.ratings.movieId=ratings_df.movieId.apply(lambda x:self.movieid2idx[x])
    self.ratings.userId=ratings_df.userId.apply(lambda x:self.userid2idx[x])

    self.x=self.ratings.drop(['rating','timestamp'],axis=1).values
    self.y=self.ratings['rating'].values
    self.x ,self.y=torch.tensor(self.x) ,torch.tensor(self.y)


  def __getitem__(self,index):
      return (self.x[index] , self.y[index])

  def __len__(self):
      return len(self.ratings)

num_epochs=128
cuda=torch.cuda.is_available()

print("Is running on GPU :", cuda)

model=MatrixFactorization(n_users,n_items,n_factors=8)
print(model)

for name ,param in  model.named_parameters():
  if param.requires_grad:
    print(name,param.data)

if cuda:
  model=model.cuda()

loss_fn=torch.nn.MSELoss()

optimizer=torch.optim.Adam(model.parameters(),lr=1e-3)

train_set=loader()
train_loader=DataLoader(train_set,128,shuffle=True)

for it  in tqdm(range(num_epochs)):
  losses=[]
  for x,y in train_loader:
    if cuda:
      x,y=x.cuda(),y.cuda()
      optimizer.zero_grad()
      outputs=model(x)
      loss=loss_fn(outputs.squeeze(),y.type(torch.float32))
      losses.append(loss.item())
      loss.backward()
      optimizer.step()
  print('iter #{}'.format(it),"loss:",sum(losses)/len(losses))

c=0
uw=0
iw=0
for name,param in model.named_parameters():
  if param.requires_grad:
    print(name,param.data)
    if c==0:
      uw=param.data
      c+=1
    else:
      iw=param.data

trained_movie_embeddings=model.item_factors.weight.data.cpu().numpy()

trained_movie_embeddings

from sklearn.cluster import KMeans

kmeans=KMeans(n_clusters=10,random_state=0).fit(trained_movie_embeddings)

for cluster in range(10):
  print('Cluster #{}'.format(cluster))
  movs=[]
  for movidx in np.where(kmeans.labels_==cluster)[0]:
    movid=train_set.idx2movieid[movidx]
    rat_count=ratings_df.loc[ratings_df['movieId']==movid].count().iloc[0]
    movs.append((movies_names[movid],rat_count))
  for mov in sorted(movs,key=lambda tup:tup[1] ,reverse=True)[:10]:
    print('\t ',mov[0])